{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Francisakinrinade/Darey.io-Projects/blob/main/2_real_time_data_streaming_kafka.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a31c0e5f",
      "metadata": {
        "id": "a31c0e5f"
      },
      "source": [
        "\n",
        "üé• Recommended Video: [Apache Kafka in 6 minutes](https://www.youtube.com/watch?v=Ch5VhJzaoaI)\n",
        "üé• Recommended Video: [Apache Kafka Fundamentals You Should Know](https://www.youtube.com/watch?v=-RDyEFvnTXI)\n",
        "\n",
        "\n",
        "### **The Never-Ending Buffet ‚Äì Mastering Data Streaming with Kafka**\n",
        "\n",
        "Welcome to the kitchen of the future, where data is the main ingredient, and real-time processing is the recipe for success. Today, we‚Äôre diving into the world of **data streaming**, where the orders never stop, and the stakes are high. By the end of this lecture, you‚Äôll understand how to build a real-time data pipeline using **Apache Kafka**, one of the most powerful tools for handling streaming data.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. The Problem: A Flood of Orders**\n",
        "Imagine your restaurant is the hottest spot in town. Orders are pouring in from every direction‚Äîonline, in-person, and even from food delivery apps. Your robot chefs are efficient, but they need a system that can handle the constant flow of data without dropping a single order. This is the challenge of **data streaming**: processing continuous, real-time data streams efficiently and reliably.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. The Solution: The Conveyor Belt of Data**\n",
        "In our kitchen, the conveyor belt is the backbone of operations. It ensures that every order reaches the right chef at the right time. In the world of data, this conveyor belt is powered by **Apache Kafka** (or alternatives like **AWS Kinesis**). Kafka acts as a distributed messaging system that can handle massive amounts of data in real-time, ensuring no order is lost or delayed.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. How Kafka Works**\n",
        "Kafka is like a well-organized kitchen with three key components:\n",
        "1. **Producers**: These are the waiters who take orders and place them on the conveyor belt. In Kafka, producers send data (messages) to a **topic**, which is like a specific lane on the conveyor belt.\n",
        "2. **Topics**: These are the lanes on the conveyor belt. Each topic is dedicated to a specific type of data (e.g., pizza orders, drink orders).\n",
        "3. **Consumers**: These are the robot chefs who pick up orders from the conveyor belt and process them. In Kafka, consumers read data from topics and perform actions based on the messages.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Building the Kitchen: Kafka in Action**\n",
        "Let‚Äôs build our data streaming pipeline step by step. We‚Äôll start by setting up a Kafka producer to send orders and a Kafka consumer to process them.\n",
        "\n",
        "#### **Step 1: Setting Up Kafka**\n",
        "Before we start coding, make sure you have Kafka installed and running. You can download it from the [official Apache Kafka website](https://kafka.apache.org/). Once installed, start the Kafka server and create a topic called `orders`.\n",
        "\n",
        "```bash\n",
        "# Start Zookeeper (required for Kafka)\n",
        "bin/zookeeper-server-start.sh config/zookeeper.properties\n",
        "\n",
        "# Start Kafka server\n",
        "bin/kafka-server-start.sh config/server.properties\n",
        "\n",
        "# Create a topic named 'orders'\n",
        "bin/kafka-topics.sh --create --topic orders --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **Step 2: The Producer ‚Äì Sending Orders**\n",
        "The producer is like the waiter who takes orders and places them on the conveyor belt. Here‚Äôs how you can create a Kafka producer in Python:\n",
        "\n",
        "```python\n",
        "from kafka import KafkaProducer\n",
        "\n",
        "# Create a Kafka producer\n",
        "producer = KafkaProducer(bootstrap_servers='localhost:9092')\n",
        "\n",
        "# Send an order to the 'orders' topic\n",
        "order = \"Pizza Order #123\"\n",
        "producer.send('orders', order.encode('utf-8'))\n",
        "\n",
        "print(f\"Sent: {order}\")\n",
        "```\n",
        "\n",
        "In this example, the producer sends a simple message (`Pizza Order #123`) to the `orders` topic. You can imagine this as a waiter placing an order on the conveyor belt.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Step 3: The Consumer ‚Äì Processing Orders**\n",
        "The consumer is like the robot chef who picks up orders from the conveyor belt and processes them. Here‚Äôs how you can create a Kafka consumer in Python:\n",
        "\n",
        "```python\n",
        "from kafka import KafkaConsumer\n",
        "\n",
        "# Create a Kafka consumer\n",
        "consumer = KafkaConsumer('orders', bootstrap_servers='localhost:9092')\n",
        "\n",
        "# Process orders as they arrive\n",
        "print(\"Listening for orders...\")\n",
        "for message in consumer:\n",
        "    order = message.value.decode('utf-8')\n",
        "    print(f\"Processing: {order}\")\n",
        "```\n",
        "\n",
        "In this example, the consumer listens to the `orders` topic and processes each order as it arrives. Think of this as the robot chef picking up an order and preparing the dish.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Scaling the Kitchen**\n",
        "Now that we have a basic pipeline, let‚Äôs talk about scaling. In a real-world scenario, your restaurant might receive thousands of orders per second. How do you handle that? Kafka is designed to scale horizontally, meaning you can add more producers, consumers, and even partitions (sub-lanes within a topic) to handle the increased load.\n",
        "\n",
        "For example:\n",
        "- **Multiple Producers**: You can have multiple waiters (producers) sending orders to the same topic.\n",
        "- **Multiple Consumers**: You can have multiple robot chefs (consumers) working in parallel to process orders faster.\n",
        "- **Partitions**: You can split a topic into multiple partitions, allowing consumers to process orders in parallel.\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Real-World Applications**\n",
        "Data streaming isn‚Äôt just for restaurants. It‚Äôs used in a wide range of industries:\n",
        "- **E-commerce**: Processing real-time transactions and updating inventory.\n",
        "- **Social Media**: Handling live feeds and notifications.\n",
        "- **IoT**: Monitoring and processing data from sensors in real-time.\n",
        "- **Finance**: Detecting fraudulent transactions as they happen.\n",
        "\n",
        "---\n",
        "\n",
        "### **7. Challenges and Best Practices**\n",
        "While Kafka is powerful, it‚Äôs not without its challenges:\n",
        "- **Data Loss**: Ensure your pipeline is fault-tolerant by using acknowledgments and replication.\n",
        "- **Latency**: Optimize your consumers to process data as quickly as possible.\n",
        "- **Scalability**: Monitor your Kafka cluster and scale it as needed to handle increased loads.\n",
        "\n",
        "---\n",
        "\n",
        "### **8. Hands-On Activity**\n",
        "Let‚Äôs put your skills to the test! Here‚Äôs a challenge for you:\n",
        "1. Modify the producer to send multiple orders in a loop.\n",
        "2. Modify the consumer to simulate processing time (e.g., sleep for 2 seconds for each order).\n",
        "3. Add a second consumer and observe how Kafka distributes the workload.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion: The Future of Real-Time Data**\n",
        "Just like the never-ending buffet, data streaming is a continuous process that requires precision, scalability, and efficiency. With tools like Kafka, you can build robust pipelines that handle real-time data with ease. Whether you‚Äôre running a restaurant, an e-commerce platform, or a social media network, mastering data streaming will give you the edge you need to stay ahead in today‚Äôs fast-paced world.\n",
        "\n",
        "So, what are you waiting for? Fire up Kafka, start streaming, and let‚Äôs build the kitchen of the future! üöÄüçï"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78ed1078",
      "metadata": {
        "id": "78ed1078"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}